{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0461b0b5-830e-423e-89e8-f13be8cbb5ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647519373490,
     "user": {
      "displayName": "Achille Bailly",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08818389123052568032"
     },
     "user_tz": -60
    },
    "id": "0461b0b5-830e-423e-89e8-f13be8cbb5ca",
    "outputId": "73fca627-0d50-47a1-8f2a-244db0747f54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danish/Documents/Driver2Vec/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pywt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fdf22-4599-4c24-99f6-0157b67c183c",
   "metadata": {
    "id": "2b9fdf22-4599-4c24-99f6-0157b67c183c",
    "tags": []
   },
   "source": [
    "## Wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aab9c59-2b06-4377-b613-33aa26226589",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1647520697786,
     "user": {
      "displayName": "Achille Bailly",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08818389123052568032"
     },
     "user_tz": -60
    },
    "id": "8aab9c59-2b06-4377-b613-33aa26226589",
    "outputId": "18bfd94a-a711-4ed4-ba0c-85831c6692ef"
   },
   "outputs": [],
   "source": [
    "def van_haar(data):\n",
    "    ncol = data.shape[1]\n",
    "    nrow = data.shape[0]\n",
    "    for i in range(ncol):\n",
    "        cur_col = data[:,i].copy()\n",
    "        (cA, cD) = pywt.dwt(cur_col, 'haar')\n",
    "        new_col = np.reshape(np.concatenate((cA,cD), 0),(nrow,1))\n",
    "        data = np.hstack((data,new_col))\n",
    "    data = data.reshape(nrow,-1)\n",
    "    return data\n",
    "\n",
    "#van_haar(test.to_numpy()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160ea70-e4e5-4800-93f3-f12256429544",
   "metadata": {
    "id": "0160ea70-e4e5-4800-93f3-f12256429544"
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84904e04-a87e-4229-a049-5c93e8bfe4b1",
   "metadata": {
    "id": "84904e04-a87e-4229-a049-5c93e8bfe4b1"
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            n_inputs, \n",
    "            n_outputs, \n",
    "            kernel_size, \n",
    "            stride,\n",
    "            dilation,\n",
    "            padding,\n",
    "            dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(\n",
    "            nn.Conv1d(\n",
    "                n_inputs,\n",
    "                n_outputs,\n",
    "                kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(\n",
    "            nn.Conv1d(\n",
    "                n_outputs,\n",
    "                n_outputs,\n",
    "                kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.chomp1,\n",
    "            self.relu1,\n",
    "            self.dropout1,\n",
    "            self.conv2,\n",
    "            self.chomp2,\n",
    "            self.relu2,\n",
    "            self.dropout2)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(\n",
    "            n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, \n",
    "                                     out_channels, \n",
    "                                     kernel_size, \n",
    "                                     stride=1, \n",
    "                                     dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, \n",
    "                                     dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37282df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_transform(tensor):\n",
    "    array = tensor.numpy()\n",
    "    out1, out2= pywt.dwt(array, \"haar\")\n",
    "    out1 = torch.from_numpy(out1)\n",
    "    out2 = torch.from_numpy(out2)\n",
    "    \n",
    "    #concatenate each channel to be able to concatenate it to the untransformed data\n",
    "    #everything will then be split when fed to the network\n",
    "    return torch.cat((out1, out2),-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ed31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPart(nn.Module):\n",
    "\n",
    "    def __init__(self,input_length, input_size, output_size):\n",
    "        super(WaveletPart, self).__init__()\n",
    "\n",
    "        # used two different layers here as in the paper but in the github code, they are the same\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.fc2 = nn.Linear(input_size, output_size)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.input_length = input_length\n",
    "\n",
    "        self.haar = reference_transform\n",
    "\n",
    "    def init_weight(self):\n",
    "        self.fc1.weight.data.normal_(0, 0.01)\n",
    "        self.fc1.bias.data.normal_(0, 0.01)\n",
    "        self.fc2.weight.data.normal_(0, 0.01)\n",
    "        self.fc2.bias.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # split the wavelet transformed data along third dim\n",
    "        x1, x2 = torch.split(x, self.input_length//2, 2)\n",
    "\n",
    "        # reshape everything to feed to the linear layer\n",
    "        bsize = x.size()[0]\n",
    "        x1 = self.fc1(x1.reshape((bsize, -1, 1)).squeeze())\n",
    "        x2 = self.fc2(x2.reshape((bsize, -1, 1)).squeeze())\n",
    "        x1 = x1.reshape(bsize, -1)\n",
    "        x2 = x2.reshape(bsize, -1)\n",
    "        return torch.cat((x1,x2),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b463b9dc-6eab-401e-a927-c7f00b3de9d0",
   "metadata": {
    "id": "b463b9dc-6eab-401e-a927-c7f00b3de9d0"
   },
   "outputs": [],
   "source": [
    "class Driver2Vec(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size, \n",
    "            input_length, \n",
    "            num_channels,\n",
    "            output_size, \n",
    "            kernel_size, \n",
    "            dropout,\n",
    "            do_wavelet = True,\n",
    "            fc_output_size = 15):\n",
    "        super(Driver2Vec, self).__init__()\n",
    "        \n",
    "        self.tcn = TemporalConvNet(input_size, \n",
    "                                   num_channels, \n",
    "                                   kernel_size=kernel_size, \n",
    "                                   dropout=dropout)\n",
    "        self.wavelet = do_wavelet\n",
    "        if self.wavelet:\n",
    "            self.haar = WaveletPart(input_length, input_size*input_length//2, fc_output_size)\n",
    "\n",
    "            linear_size = num_channels[-1] + fc_output_size*2\n",
    "        else: \n",
    "            linear_size = num_channels[-1]\n",
    "        self.input_length = input_length\n",
    "\n",
    "        self.input_bn = nn.LayerNorm(linear_size)\n",
    "        self.linear = nn.Linear( linear_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, print_temp = False):\n",
    "        \"\"\"Inputs have to have dimension (N, C_in, L_in*2)\n",
    "        the base time series, and the two wavelet transform channel are concatenated along dim2\"\"\"\n",
    "        \n",
    "        # split the inputs, in the last dim, first is the unchanged data, then \n",
    "        # the wavelet transformed data\n",
    "        input_tcn, input_haar = torch.split(inputs, self.input_length, 2)\n",
    "\n",
    "        # feed each one to their corresponding network\n",
    "        y1 = self.tcn(input_tcn)\n",
    "        y1 = y1[:,:,-1] # for the TCN, only the last output element interests us\n",
    "\n",
    "        if self.wavelet:\n",
    "            y2 = self.haar(input_haar)\n",
    "\n",
    "            out = torch.cat((y1,y2),1)\n",
    "            bsize = out.shape[0]\n",
    "\n",
    "        if bsize > 0: # issue when the batch size is 1, can't batch normalize it\n",
    "            out = self.input_bn(out)\n",
    "        else:\n",
    "            out = out\n",
    "        out = self.linear(out)\n",
    "\n",
    "        if print_temp:\n",
    "            print(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643074c4-0c64-4a6d-b79f-b560db0d3754",
   "metadata": {
    "id": "643074c4-0c64-4a6d-b79f-b560db0d3754"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def preprocess(df):\n",
    "    return (\n",
    "        df.drop(\n",
    "            [\"FOG\",\n",
    "             \"FOG_LIGHTS\",\n",
    "             \"FRONT_WIPERS\",\n",
    "             \"HEAD_LIGHTS\",\n",
    "             \"RAIN\",\n",
    "             \"REAR_WIPERS\",\n",
    "             \"SNOW\",\n",
    "            ], axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def load_dataset(input_dir):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for dir,_,files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            label = int(file.split(\"_\")[1])-1\n",
    "            df = pd.read_csv(dir + \"/\" + file, index_col=0)\n",
    "            df = preprocess(df).to_numpy().transpose()\n",
    "            x.append(torch.from_numpy(df).float())\n",
    "            y.append(label)\n",
    "    return x,y\n",
    "        \n",
    "\n",
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data, labels, input_length=500):\n",
    "        'Initialization'\n",
    "        self.data, self.labels = data, labels\n",
    "        self.index = [i for i in range(len(self.data))]\n",
    "        self.length = input_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        max_length = self.data[index].shape[1]\n",
    "        start_pos_anchor = int(np.random.uniform(0,max_length - self.length+1))\n",
    "        X_anchor = self.data[index][:,start_pos_anchor:start_pos_anchor+self.length]\n",
    "        anchor_wvlt = reference_transform(X_anchor)\n",
    "        y_anchor = self.labels[index]\n",
    "\n",
    "        # create list of possible positive index samples\n",
    "        positive_list = [\n",
    "            i for i in self.index if self.labels[i] == y_anchor and i != index]\n",
    "        positive_index = np.random.choice(positive_list)\n",
    "\n",
    "        max_length = self.data[positive_index].shape[1]\n",
    "        start_pos_positive = int(np.random.uniform(0,max_length - self.length+1))\n",
    "\n",
    "        positive = self.data[positive_index][:,start_pos_positive:start_pos_positive+self.length]\n",
    "        # get the wavelet transform of that sample (the two channels are concatenated along the last dim)\n",
    "        positive_wvlt = reference_transform(positive)\n",
    "        \n",
    "        # same here\n",
    "        negative_list = [\n",
    "            i for i in self.index if self.labels[i] != y_anchor]\n",
    "        negative_index = np.random.choice(negative_list)\n",
    "\n",
    "        max_length = self.data[negative_index].shape[1]\n",
    "        start_pos_negative = int(np.random.uniform(0,max_length - self.length+1))\n",
    "\n",
    "        negative = self.data[negative_index][:,start_pos_negative:start_pos_negative+self.length]\n",
    "        negative_wvlt = reference_transform(negative)\n",
    "\n",
    "        # concatenate the data for the TCN and the haar wavelet transform\n",
    "        # they will be split in the forward pass\n",
    "        return torch.cat((X_anchor, anchor_wvlt),1), \\\n",
    "            torch.cat((positive, positive_wvlt),1), \\\n",
    "            torch.cat((negative, negative_wvlt),1), \\\n",
    "            y_anchor\n",
    "\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Is to be used with Dataloader for testing only\n",
    "    \"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        wvlt = reference_transform(x)\n",
    "        out = torch.cat((x,wvlt), 1)\n",
    "        return out, self.labels[index]\n",
    "        \n",
    "\n",
    "class FromFiles:\n",
    "    \"\"\"\n",
    "    Used to load the data from the files and split between test and train sets\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dir, input_length):\n",
    "        self.input_dir = input_dir\n",
    "        self.input_length = input_length\n",
    "\n",
    "        self.data, self.labels = self.__load_dataset()\n",
    "        self.index = [i for i in range(len(self.data))]\n",
    "\n",
    "    def __load_dataset(self):\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for dir,_,files in os.walk(self.input_dir):\n",
    "            for file in files:\n",
    "                label = int(file.split(\"_\")[1])-1\n",
    "                df = pd.read_csv(dir + \"/\" + file, index_col=0)\n",
    "                df = preprocess(df).to_numpy().transpose()\n",
    "                x.append(torch.from_numpy(df).float())\n",
    "                y.append(label)\n",
    "        return x,y\n",
    "\n",
    "\n",
    "    def split_train_test(self):\n",
    "        x_test, y_test = [], []\n",
    "        for label in range(5):\n",
    "            possible_list = [i for i in self.index if self.labels[i] == label]\n",
    "            choosen_index = np.random.choice(possible_list)\n",
    "\n",
    "            positive = self.data[choosen_index]\n",
    "            max_length = positive.shape[1]\n",
    "            train, test = torch.split(positive, [max_length-self.input_length, self.input_length], dim=1)\n",
    "\n",
    "            x_test.append(test)\n",
    "            y_test.append(label)\n",
    "            self.data[choosen_index] = train\n",
    "            \n",
    "        return self.data, self.labels, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ad9181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Driver2Vec(\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(31, 32, kernel_size=(16,), stride=(1,), padding=(15,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(16,), stride=(1,), padding=(15,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(31, 32, kernel_size=(16,), stride=(1,), padding=(15,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "          (4): Conv1d(32, 32, kernel_size=(16,), stride=(1,), padding=(15,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(31, 32, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (haar): WaveletPart(\n",
       "    (fc1): Linear(in_features=6200, out_features=15, bias=True)\n",
       "    (fc2): Linear(in_features=6200, out_features=15, bias=True)\n",
       "  )\n",
       "  (input_bn): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=62, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels = 31\n",
    "input_length = 400\n",
    "channel_sizes = [32]\n",
    "output_size = 62\n",
    "kernel_size = 16\n",
    "dropout = 0.1\n",
    "model = Driver2Vec(input_channels, input_length, channel_sizes, output_size, kernel_size=kernel_size, dropout=dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3692f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datasets parameters\n",
    "params = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}\n",
    "\n",
    "\n",
    "fromfiles= FromFiles(\"./dataset\", input_length)\n",
    "x_train, y_train, x_test, y_text = fromfiles.split_train_test()\n",
    "training_set = TrainDataset(x_train, y_train, input_length)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "loss = nn.TripletMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec33b00d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m      5\u001b[0m     loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m anchor, positive, negative, label \u001b[38;5;129;01min\u001b[39;00m training_generator:\n",
      "File \u001b[0;32m~/Documents/Driver2Vec/venv/lib/python3.9/site-packages/tqdm/notebook.py:242\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    241\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Driver2Vec/venv/lib/python3.9/site-packages/tqdm/notebook.py:118\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    120\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "model.train()\n",
    "for epoch in (pbar := tqdm(range(epochs))):\n",
    "    loss_list = []\n",
    "    for anchor, positive, negative, label in training_generator:\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        y_anchor = model(anchor)\n",
    "        y_positive = model(positive)\n",
    "        y_negative = model(negative)\n",
    "\n",
    "        loss_value = loss(y_anchor, y_positive, y_negative)\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss_value.cpu().detach().numpy())\n",
    "    #print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(loss_list)))\n",
    "    pbar.set_description(\"Loss: %0.5g, Epochs\" % np.mean(loss_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 1}\n",
    "\n",
    "classifier_train_set = TrainDataset(x_test, y_text, input_length)\n",
    "classifier_train_generator = DataLoader(training_set, **params)\n",
    "\n",
    "x_train_classifier = []\n",
    "y_train_classifier = []\n",
    "for data,_, _, label in classifier_train_generator:\n",
    "\n",
    "    data = data.to(device)\n",
    "    embed = model(data)\n",
    "\n",
    "    y = np.zeros(5, dtype=int)\n",
    "    y[label-1] = 1\n",
    "\n",
    "    x_train_classifier.append(embed.cpu().detach().numpy().squeeze())\n",
    "    y_train_classifier.append(int(label))\n",
    "\n",
    "x_train_classifier = np.array(x_train_classifier)\n",
    "y_train_classifier = np.array(y_train_classifier)\n",
    "\n",
    "lgb_train = lgbm.Dataset(x_train_classifier, y_train_classifier)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class':5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'max_depth': 12,\n",
    "    'num_trees': 100,\n",
    "    'verbose': 0,\n",
    "    'min_data_in_leaf': 2 # May need to change that with a real test set\n",
    "}\n",
    "\n",
    "clf = lgbm.train(params,lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 1}\n",
    "\n",
    "classifier_test_set = TestDataset(x_test, y_text)\n",
    "classifier_test_generator = DataLoader(classifier_test_set, **params)\n",
    "\n",
    "x_test_classifier = []\n",
    "y_test_classifier = []\n",
    "for data, label in classifier_test_generator:\n",
    "    data = data.to(device)\n",
    "    embed = model(data)\n",
    "\n",
    "    y = np.zeros(5, dtype=int)\n",
    "    y[label-1] = 1\n",
    "\n",
    "    x_test_classifier.append(embed.cpu().detach().numpy().squeeze())\n",
    "    y_test_classifier.append(int(label))\n",
    "\n",
    "\n",
    "y_pred = clf.predict(x_test_classifier)\n",
    "print(y_pred, y_test_classifier)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tcn-testing.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/AchilleBailly/Driver2Vec/blob/kick-off/tcn-testing.ipynb",
     "timestamp": 1647516778114
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
